{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File structure\n",
    ">WORKSPACE_DIR(.)\n",
    ">>PRJ_NAME.ipynb  \n",
    ">>PRJ_NAME_get_data.ipynb  \n",
    ">>PRJ_NAME_train_model.ipynb   \n",
    ">>DATA_PATH(datasets)  \n",
    ">>>PRJ_NAME  \n",
    ">>>>TRAIN_DIR(train)  \n",
    ">>>>>CLASS_1_DIR  \n",
    ">>>>>CLASS_n_DIR  \n",
    "\n",
    ">>>>VALIDATION_DIR(validation)  \n",
    ">>>>>CLASS_1_DIR  \n",
    ">>>>>CLASS_n_DIR  \n",
    "\n",
    ">>>>TEST_DIR(test)\n",
    ">>>>>CLASS_1_DIR  \n",
    ">>>>>CLASS_n_DIR  \n",
    "\n",
    ">>MODEL_PATH(models)  \n",
    ">>>PRJ_NAME  \n",
    "\n",
    ">>Image_PATH(images)  \n",
    ">>>PRJ_NAME  \n",
    "\n",
    ">>LOG_PATH(logs)  \n",
    ">>>PRJ_NAME  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "rand_seed=99\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(rand_seed)\n",
    "\n",
    "PRJ_NAME = \"face_recognition\"\n",
    "\n",
    "WORKSPACE_DIR = \".\"\n",
    "#where to save dataset\n",
    "DATA_DIR = PRJ_NAME\n",
    "DATA_PATH = os.path.join( WORKSPACE_DIR,\"datasets\",DATA_DIR )\n",
    "\n",
    "#datasets inlcude train data,validation data,test data\n",
    "TRAIN_DIR = os.path.join( DATA_PATH, 'train' )\n",
    "VALIDATION_DIR = os.path.join( DATA_PATH, 'validation' )\n",
    "TEST_DIR = os.path.join( DATA_PATH, 'test' )\n",
    "\n",
    "#where to save models\n",
    "MODEL_DIR = PRJ_NAME\n",
    "MODEL_PATH = os.path.join( WORKSPACE_DIR,\"models\",MODEL_DIR )\n",
    "\n",
    "# where to save figures\n",
    "IMAGE_DIR = PRJ_NAME\n",
    "IMAGE_PATH = os.path.join( WORKSPACE_DIR,\"images\",IMAGE_DIR )\n",
    "\n",
    "#where to save logs\n",
    "LOG_DIR = PRJ_NAME\n",
    "LOG_PATH = os.path.join( WORKSPACE_DIR,\"logs\",LOG_DIR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training jarvis images: 389\n",
      "total training other images: 387\n",
      "total validation jarvis images: 396\n",
      "total validation other images: 390\n",
      "total test jarvis images: 196\n",
      "total test other images: 196\n"
     ]
    }
   ],
   "source": [
    "#this is a binary classificationï¼Œ\n",
    "#so every datafile inlcudes two classfiles,jarvis & other\n",
    "#note: you can use face_recogniton_get_data.ipynb to generate your face dataset\n",
    "train_jarvis_dir = os.path.join( TRAIN_DIR, 'jarvis' )\n",
    "train_other_dir = os.path.join( TRAIN_DIR, 'other' )\n",
    "validation_jarvis_dir = os.path.join( VALIDATION_DIR, 'jarvis' )\n",
    "validation_other_dir = os.path.join( VALIDATION_DIR, 'other' )\n",
    "test_jarvis_dir = os.path.join( TEST_DIR, 'jarvis' )\n",
    "test_other_dir = os.path.join( TEST_DIR, 'other' )\n",
    "#show the number of datafiles\n",
    "print('total training jarvis images:', len(os.listdir(train_jarvis_dir)))\n",
    "print('total training other images:', len(os.listdir(train_other_dir)))\n",
    "print('total validation jarvis images:', len(os.listdir(validation_jarvis_dir)))\n",
    "print('total validation other images:', len(os.listdir(validation_other_dir)))\n",
    "print('total test jarvis images:', len(os.listdir(test_jarvis_dir)))\n",
    "print('total test other images:', len(os.listdir(test_other_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jarvis\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#import face_detect file path from cv2\n",
    "#you should change this filepath fit your environment\n",
    "cascade_path = \"C:/Users/jarvis/AppData/Local/conda/conda/envs/tensorflow/Library/etc/haarcascades/haarcascade_frontalface_alt2.xml\"  \n",
    "#before import keras,you should make sure TensorFlow, CNTK, or Theano had been installed\n",
    "import keras\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CatchVideo(window_name, camera_idx):\n",
    "    #new a window,the name is window_name\n",
    "    cv2.namedWindow(window_name)\n",
    "    \n",
    "    #open camera\n",
    "    cap = cv2.VideoCapture(camera_idx)                \n",
    "    \n",
    "    #load detect face classfier\n",
    "    classfier = cv2.CascadeClassifier(cascade_path)\n",
    "    \n",
    "    #set green rectangle to show face\n",
    "    color = (0, 255, 0)\n",
    "    #load the model whick had been trained\n",
    "    #note: you can use face_recogniton_train_model.ipynb to train and save model\n",
    "    model = models.load_model(filepath=MODEL_PATH+\"/weights.hdf5\")  \n",
    "    result=0\n",
    "    while cap.isOpened():\n",
    "        #read frame\n",
    "        _, frame = cap.read()\n",
    "        \n",
    "        #rgb2gray\n",
    "        grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)                 \n",
    "        \n",
    "        #face detect\n",
    "        faceRects = classfier.detectMultiScale(grey, scaleFactor = 1.2, minNeighbors = 3, minSize = (32, 32))\n",
    "        if len(faceRects) > 0:                                               \n",
    "            for faceRect in faceRects:  \n",
    "                x, y, w, h = faceRect\n",
    "               \n",
    "                if (x >= 11) and (y >= 11):#leave distance between edge and face detected\n",
    "                    img = frame[y - 10: y + h + 10, x - 10: x + w + 10]\n",
    "                    cv2.rectangle(frame, (x - 10, y - 10), (x + w + 10, y + h + 10), color, 2)\n",
    "\n",
    "                    img_size= img.shape\n",
    "#                    print(\"x \",x,\"y \",y,\"w \",w,\"h \",w,\"iw \",img_size[0],\"ih \",img_size[1])\n",
    "\n",
    "                    img = cv2.resize(img,(100,100))                   \n",
    "                    tmp_img = np.expand_dims(img,axis = 0) / 255\n",
    "                    result = model.predict(tmp_img)\n",
    "                    if (result < 0.5):\n",
    "                        cv2.putText(frame,'jarvis',(x + 20, y + 20),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1,(255,255,255))\n",
    "                    else:\n",
    "                        cv2.putText(frame,'other',(x + 20, y + 20),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                    1,(255,255,255))\n",
    "                else:\n",
    "                    pass\n",
    "                        \n",
    "        #display frame & press q-key exit\n",
    "        cv2.imshow(window_name, frame)        \n",
    "        c = cv2.waitKey(2)\n",
    "        if c & 0xFF == ord('q'):\n",
    "            break        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatchVideo(PRJ_NAME,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
